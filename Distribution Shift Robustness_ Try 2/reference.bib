@misc{hendrycks2019benchmarking,
      title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations}, 
      author={Dan Hendrycks and Thomas Dietterich},
      year={2019},
      eprint={1903.12261},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hendrycks2021faces,
      title={The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization}, 
      author={Dan Hendrycks and Steven Basart and Norman Mu and Saurav Kadavath and Frank Wang and Evan Dorundo and Rahul Desai and Tyler Zhu and Samyak Parajuli and Mike Guo and Dawn Song and Jacob Steinhardt and Justin Gilmer},
      year={2021},
      eprint={2006.16241},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{wang2019learning,
    author = {Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {Learning Robust Global Representations by Penalizing Local Predictive Power},
    url = {https://proceedings.neurips.cc/paper/2019/file/3eefceb8087e964f89c2d59e8a249915-Paper.pdf},
    volume = {32},
    year = {2019}
}

@misc{hendrycks2021natural,
      title={Natural Adversarial Examples}, 
      author={Dan Hendrycks and Kevin Zhao and Steven Basart and Jacob Steinhardt and Dawn Song},
      year={2021},
      eprint={1907.07174},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{zhang2018mixup,
      title={mixup: Beyond Empirical Risk Minimization}, 
      author={Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
      year={2018},
      eprint={1710.09412},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hendrycks2020augmix,
      title={AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty}, 
      author={Dan Hendrycks and Norman Mu and Ekin D. Cubuk and Barret Zoph and Justin Gilmer and Balaji Lakshminarayanan},
      year={2020},
      eprint={1912.02781},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{cubuk2019autoaugment,
      title={AutoAugment: Learning Augmentation Policies from Data}, 
      author={Ekin D. Cubuk and Barret Zoph and Dandelion Mane and Vijay Vasudevan and Quoc V. Le},
      year={2019},
      eprint={1805.09501},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{hendrycks2021pixmix,
      title={PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures}, 
      author={Dan Hendrycks and Andy Zou and Mantas Mazeika and Leonard Tang and Bo Li and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2112.05135},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{herrmann2021pyramid,
      title={Pyramid Adversarial Training Improves ViT Performance}, 
      author={Charles Herrmann and Kyle Sargent and Lu Jiang and Ramin Zabih and Huiwen Chang and Ce Liu and Dilip Krishnan and Deqing Sun},
      year={2021},
      eprint={2111.15121},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{he2021masked,
      title={Masked Autoencoders Are Scalable Vision Learners}, 
      author={Kaiming He and Xinlei Chen and Saining Xie and Yanghao Li and Piotr Dollár and Ross Girshick},
      year={2021},
      eprint={2111.06377},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{mao2021robust,
      title={Towards Robust Vision Transformer}, 
      author={Xiaofeng Mao and Gege Qi and Yuefeng Chen and Xiaodan Li and Ranjie Duan and Shaokai Ye and Yuan He and Hui Xue},
      year={2021},
      eprint={2105.07926},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{paul2021vision,
      title={Vision Transformers are Robust Learners}, 
      author={Sayak Paul and Pin-Yu Chen},
      year={2021},
      eprint={2105.07581},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{liu2022convnet,
      title={A ConvNet for the 2020s}, 
      author={Zhuang Liu and Hanzi Mao and Chao-Yuan Wu and Christoph Feichtenhofer and Trevor Darrell and Saining Xie},
      year={2022},
      eprint={2201.03545},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{koh2021wilds,
      title={WILDS: A Benchmark of in-the-Wild Distribution Shifts}, 
      author={Pang Wei Koh and Shiori Sagawa and Henrik Marklund and Sang Michael Xie and Marvin Zhang and Akshay Balsubramani and Weihua Hu and Michihiro Yasunaga and Richard Lanas Phillips and Irena Gao and Tony Lee and Etienne David and Ian Stavness and Wei Guo and Berton A. Earnshaw and Imran S. Haque and Sara Beery and Jure Leskovec and Anshul Kundaje and Emma Pierson and Sergey Levine and Chelsea Finn and Percy Liang},
      year={2021},
      eprint={2012.07421},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{sagawa2021extending,
      title={Extending the WILDS Benchmark for Unsupervised Adaptation}, 
      author={Shiori Sagawa and Pang Wei Koh and Tony Lee and Irena Gao and Sang Michael Xie and Kendrick Shen and Ananya Kumar and Weihua Hu and Michihiro Yasunaga and Henrik Marklund and Sara Beery and Etienne David and Ian Stavness and Wei Guo and Jure Leskovec and Kate Saenko and Tatsunori Hashimoto and Sergey Levine and Chelsea Finn and Percy Liang},
      year={2021},
      eprint={2112.05090},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{steiner2021train,
      title={How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers}, 
      author={Andreas Steiner and Alexander Kolesnikov and Xiaohua Zhai and Ross Wightman and Jakob Uszkoreit and Lucas Beyer},
      year={2021},
      eprint={2106.10270},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{geirhos2019imagenettrained,
      title={ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness}, 
      author={Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},
      year={2019},
      eprint={1811.12231},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{cubuk2019randaugment,
      title={RandAugment: Practical automated data augmentation with a reduced search space}, 
      author={Ekin D. Cubuk and Barret Zoph and Jonathon Shlens and Quoc V. Le},
      year={2019},
      eprint={1909.13719},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{vaswani2017attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{dosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{alamar2018illustrated, 
    title={The Illustrated Transformer}, 
    url={https://jalammar.github.io/illustrated-transformer/}, 
    journal={The Illustrated Transformer}, 
    author={Alammar, Jay}, 
    year={2018}, 
    month={Jun}
}

@misc{morrison2021exploring,
      title={Exploring Corruption Robustness: Inductive Biases in Vision Transformers and MLP-Mixers}, 
      author={Katelyn Morrison and Benjamin Gilby and Colton Lipchak and Adam Mattioli and Adriana Kovashka},
      year={2021},
      eprint={2106.13122},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{bhojanapalli2021understanding,
      title={Understanding Robustness of Transformers for Image Classification}, 
      author={Srinadh Bhojanapalli and Ayan Chakrabarti and Daniel Glasner and Daliang Li and Thomas Unterthiner and Andreas Veit},
      year={2021},
      eprint={2103.14586},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{
    vincent2008extracting, 
    place={Helsinki, Finland}, title={Extracting and composing robust features with denoising autoencoders}, ISBN={9781605582054}, url={http://portal.acm.org/citation.cfm?doid=1390156.1390294}, DOI={10.1145/1390156.1390294}, booktitle={Proceedings of the 25th international conference on Machine learning - ICML ’08}, publisher={ACM Press}, author={Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine}, year={2008}, pages={1096–1103} 
}

@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{sun2016deep,
      title={Deep CORAL: Correlation Alignment for Deep Domain Adaptation}, 
      author={Baochen Sun and Kate Saenko},
      year={2016},
      eprint={1607.01719},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{shi2021gradient,
      title={Gradient Matching for Domain Generalization}, 
      author={Yuge Shi and Jeffrey Seely and Philip H. S. Torr and N. Siddharth and Awni Hannun and Nicolas Usunier and Gabriel Synnaeve},
      year={2021},
      eprint={2104.09937},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{sagawa2020distributionally,
      title={Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization}, 
      author={Shiori Sagawa and Pang Wei Koh and Tatsunori B. Hashimoto and Percy Liang},
      year={2020},
      eprint={1911.08731},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{lipton2018detecting,
      title={Detecting and Correcting for Label Shift with Black Box Predictors}, 
      author={Zachary C. Lipton and Yu-Xiang Wang and Alex Smola},
      year={2018},
      eprint={1802.03916},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{arjovsky2020invariant,
      title={Invariant Risk Minimization}, 
      author={Martin Arjovsky and Léon Bottou and Ishaan Gulrajani and David Lopez-Paz},
      year={2020},
      eprint={1907.02893},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{subbaswamy2021evaluating,
      title={Evaluating Model Robustness and Stability to Dataset Shift}, 
      author={Adarsh Subbaswamy and Roy Adams and Suchi Saria},
      year={2021},
      eprint={2010.15100},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wang2021tent,
      title={Tent: Fully Test-time Adaptation by Entropy Minimization}, 
      author={Dequan Wang and Evan Shelhamer and Shaoteng Liu and Bruno Olshausen and Trevor Darrell},
      year={2021},
      eprint={2006.10726},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@InProceedings{buolamwini2018gender,
  title = 	 {Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification},
  author = 	 {Buolamwini, Joy and Gebru, Timnit},
  booktitle = 	 {Proceedings of the 1st Conference on Fairness, Accountability and Transparency},
  pages = 	 {77--91},
  year = 	 {2018},
  editor = 	 {Friedler, Sorelle A. and Wilson, Christo},
  volume = 	 {81},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--24 Feb},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf},
  url = 	 {https://proceedings.mlr.press/v81/buolamwini18a.html},
}

@book{
    quinonero2009dataset, place={Cambridge, Mass}, series={Neural information processing series}, title={Dataset shift in machine learning}, ISBN={9780262170055}, publisher={MIT Press}, year={2009}, collection={Neural information processing series}
}